# 카프카 브로커, 클러스터

## Kafka 브로커

- **Kafka 브로커**는 Kafka 클라이언트와 데이터를 주고받기 위해 사용하는 주체.
- 데이터를 분산 저장하여 장애가 발생하더라도 안전하게 사용할 수 있도록 도와주는 애플리케이션.

### 주요 기능

1. **데이터 저장 및 전송**
  - 프로듀서로부터 데이터를 전달받아 요청된 토픽의 파티션에 데이터를 저장.
  - 컨슈머 요청 시, 파티션에 저장된 데이터를 전달.
  - 데이터는 **파일 시스템**에 저장되어 안전하게 관리.
2. **페이지 캐시**
  - 디스크에서 읽은 파일의 내용을 메모리의 **페이지 캐시**에 저장.
  - 동일한 파일 접근 시 메모리에서 직접 읽어 속도를 향상.
  - 페이지 캐시를 활용하여 Kafka는 추가적인 캐시 구현 없이 효율적으로 작동.
  - 이로 인해 Kafka 브로커 실행 시 **힙 메모리 사이즈를 크게 설정할 필요가 없다.**

---

## Kafka 클러스터

- **Kafka 클러스터**는 3대 이상의 브로커 서버를 하나의 클러스터로 묶어 운영.
- 클러스터로 묶인 브로커는 프로듀서가 보낸 데이터를 안전하게 **분산 저장**하고 **복제**.

### 데이터 복제 및 싱크

- 데이터 복제는 Kafka를 **장애 허용 시스템**으로 동작하도록 지원.
- **파티션 단위**로 복제 수행.
  - **리더(leader)**: 프로듀서/컨슈머와 직접 통신.
  - **팔로워(follower)**: 리더 파티션 데이터를 복제하여 자신의 파티션에 저장.
- 복제 개수(replication factor):
  - 기본값: 1 (복제 없음)
  - 최대값: 브로커 개수
  - 복제 개수가 클수록 데이터는 안전하지만 저장 용량이 더 필요함.
- 클러스터 내 브로커 장애 시:
  - 장애가 발생한 브로커의 리더 파티션은 사용 불가 상태로 전환.
  - 팔로워 파티션 중 하나가 리더 역할을 대체.

---

## 컨트롤러와 코디네이터

1. **컨트롤러**
  - 클러스터의 다수 브로커 중 한 대가 **컨트롤러** 역할 수행.
  - 주요 역할:
    - 다른 브로커의 상태 체크.
    - 브로커 장애 발생 시 리더 파티션 재분배.
  - 컨트롤러 장애 시 다른 브로커가 역할을 대신 수행.
2. **코디네이터(coordinator)**
  - 클러스터의 다수 브로커 중 한 대가 **코디네이터** 역할 수행.
  - 주요 역할:
    - 컨슈머 그룹 상태 체크.
    - 파티션과 컨슈머를 매칭 및 재분배(리밸런싱).

---

## 데이터 삭제

- Kafka는 **컨슈머나 프로듀서가 데이터를 삭제 요청할 수 없다.**
- 브로커만 데이터 삭제 가능.
- 데이터 삭제는 **로그 세그먼트(log segment)** 단위로 이루어짐.
  - 특정 데이터를 선별해 삭제하는 기능은 없음.
  - 설정 조건에 따라 **세그먼트 단위**로 삭제.

### 관련 설정

1. **`log.segment.bytes`**
  - 세그먼트 파일 크기가 설정된 바이트에 도달하면 기존 세그먼트 파일은 닫고 새 파일 생성.
  - 기본값: `1GB`
2. **`log.segment.ms`**
  - 세그먼트 생성 후 설정된 시간이 지나면 기존 세그먼트 파일은 닫고 새 파일 생성.
  - 예: `60000ms`(60초)로 설정하면 60초 후 새 세그먼트 파일 시작.
3. **`log.retention.check.interval.ms`**
  - Kafka 브로커가 로그 삭제 정책을 확인하는 주기 설정.
  - 오래된 세그먼트를 삭제하거나 압축 처리.

⇒ 너무 작은 값을 설정하게 되면 세그먼트 파일에 대한 생성 및 닫는 작업이 많아져 부하가 발생할 수 있으므로 주의해야한다.

### 삭제 정책

- Kafka는 **`log.retention.hours`**, **`log.retention.bytes`**, **`log.retention.ms`** 설정 조건을 주기적으로 검사하여 조건을 만족하는 세그먼트를 삭제 또는 압축.

---

## 컨슈머 오프셋 저장

- 컨슈머 그룹은 데이터를 처리한 후 **어느 레코드까지 처리했는지 확인하기 위해 오프셋을 커밋.**
- 커밋된 오프셋은 Kafka의 내부 토픽인 `__consumer_offsets`에 저장.
- 컨슈머 그룹은 저장된 오프셋을 기반으로 다음 레코드를 가져감.