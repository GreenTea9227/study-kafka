### 아파치 카프카의 등장 배경과 역할

https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying

2011년 링크드인(LinkedIn)은 파편화된 데이터 수집 및 분배 아키텍처로 인해 운영에 어려움을 겪었다. 소스 애플리케이션과 타깃 애플리케이션 사이의 1:1 데이터 파이프라인은 시간이 지남에 따라 복잡도가 기하급수적으로 증가했고, 이로 인해 시스템 안정성이 저하되었다. 기존의 메시징 플랫폼과 ETL 도구를 적용해보았지만 파편화된 구조를 개선하는 데에는 한계가 있었다.이에 링크드인의 데이터팀은 새로운 시스템을 개발하기로 결정했고, 그 결과물이 바로 아파치 카프카(Apache Kafka)이다. 카프카는 데이터 파이프라인을 중앙집중화하여 소스와 타깃 애플리케이션 간의 의존성을 최소화하고, 데이터를 안정적으로 처리할 수 있게 해준다. 카프카의 핵심 구성 요소는 프로듀서(Producer), 컨슈머(Consumer), 그리고 토픽(Topic)이며, 데이터는 파티션(Partition)이라는 단위로 저장된다.

>
>
>
> ### 카프카의 핵심 구성 요소
>
> **아파치 카프카**의 핵심 구성 요소는 다음과 같다:
>
> - **프로듀서(Producer)**: 데이터를 생성하여 카프카로 전송한다.
> - **컨슈머(Consumer)**: 카프카로부터 데이터를 수신하여 처리한다.
> - **토픽(Topic)**: 특정 주제나 목적에 따라 데이터를 분류하여 저장하는 논리적 단위이다.
> - **파티션(Partition)**: 토픽을 물리적으로 분할한 단위로, 데이터의 병렬 처리를 가능하게 한다.
>
> **카프카 구성 요소 간의 관계를 나타낸 다이어그램:**
>
> ```mermaid
> graph LR
>     Producer --> |데이터 전송| Topic
>     Topic --> |데이터 저장| Partition
>     Partition --> |데이터 제공| Consumer
> 
> ```
>
> ---
>
> 이렇게 프로듀서는 데이터를 토픽으로 전송하고, 토픽은 파티션으로 구성되어 데이터를 저장한다. 컨슈머는 파티션으로부터 데이터를 수신하여 처리한다.
>
> ### 예시)
>
> ```mermaid
> graph TD
>     Producer[Producer] --> Topic[Topic]
>     Topic --> PartitionKey[Partition Key = Match Name <br> Canada vs USA]
>     PartitionKey --> Record[Record]
>     Record -->|Quarter End<br>Free Throw| Partition0[Partition 0]
>     Record -->|Score 41-46<br>Score 39-46<br>Quarter Start| Partition1[Partition 1]
>     Record -->|Foul| Partition2[Partition 2]
> 
>     Partition0 -->|Mobile Consumer| ConsumerMobile[Consumer <br> Mobile]
>     Partition1 -->|Computer Consumer| ConsumerComputer[Consumer <br> Computer]
> 
>     style Topic fill:#f9f,stroke:#333,stroke-width:2px
>     style Partition0 fill:#bbf,stroke:#333,stroke-width:2px
>     style Partition1 fill:#bbf,stroke:#333,stroke-width:2px
>     style Partition2 fill:#bbf,stroke:#333,stroke-width:2px
>     style ConsumerMobile fill:#f99,stroke:#333,stroke-width:2px
>     style ConsumerComputer fill:#99f,stroke:#333,stroke-width:2px
> 
> ```
>

### 카프카의 주요 특징

- 높은 처리량: 대용량 데이터를 묶음 단위로 처리하는 배치 전송 방식을 통해 높은 처리량을 확보한다.
- 확장성: 브로커(Broker) 수를 늘려 쉽게 스케일 아웃할 수 있으며, 필요에 따라 스케일 인도 가능하다.
- 영속성: 데이터를 파일 시스템에 저장하여 브로커 장애 시에도 데이터 손실을 방지한다.
- 고가용성: 데이터 복제를 통해 일부 브로커에 장애가 발생하더라도 시스템은 지속적으로 운영된다.

### 빅데이터 파이프라인에서의 카프카

현대의 IT 서비스는 방대한 양의 데이터를 생성하며, 이를 효율적으로 저장하고 분석하기 위해 데이터 레이크(Data Lake)를 활용한다. 카프카는 데이터 파이프라인의 핵심 요소로서, 엔드 투 엔드 방식의 파편화된 데이터 수집을 개선하고 안정성을 높인다.

카프카는 높은 처리량과 확장성, 영속성, 고가용성 등의 특징을 바탕으로 데이터 파이프라인을 안정적이고 효율적으로 운영할 수 있게 해준다.

### 데이터 아키텍처와 카프카의 미래

기존의 람다 아키텍처(Lambda Architecture)는 배치 레이어와 스피드 레이어로 나뉘어 있어 복잡성이 높았다. 이를 개선한 카파 아키텍처(Kappa Architecture)는 모든 데이터를 스트림 형태로 처리하여 단일한 데이터 처리 파이프라인을 제공한다.

제이 크렙스(Jay Kreps)는 카파 아키텍처를 발전시켜 스트리밍 데이터 레이크(Streaming Data Lake)를 제안했다. 이는 스피드 레이어에서 데이터의 저장과 처리를 모두 담당하여 데이터의 단일 진실 공급원(SSOT, Single Source Of Truth)이 되는 것을 목표로 한다.

>
>
>
> ### 람다 아키텍처(Lambda Architecture)
>
> **람다 아키텍처**는 빅데이터 시스템에서 대용량 데이터를 처리하기 위해 고안된 아키텍처이다. 데이터 처리 방식을 세 개의 레이어로 구분한다:
>
> 1. **배치 레이어(Batch Layer)**: 대용량의 정적 데이터(batch data)를 일괄 처리하여 정확한 결과를 생성한다.
> 2. **스피드 레이어(Speed Layer)**: 실시간 데이터(stream data)를 빠르게 처리하여 최신 정보를 제공한다.
> 3. **서빙 레이어(Serving Layer)**: 배치 레이어와 스피드 레이어에서 처리된 결과를 통합하여 사용자에게 제공한다.
>
> 이러한 구조는 실시간 처리와 일괄 처리를 분리함으로써 정확성과 최신성을 모두 만족시키지만, 두 개의 레이어에서 동일한 로직을 중복 구현해야 하는 복잡성이 있다.
>
> **람다 아키텍처 구조도:**
>
> ```mermaid
> graph LR
>     subgraph 배치 레이어
>         A[데이터 수집]
>         B[데이터 저장]
>         C[일괄 처리]
>     end
>     subgraph 스피드 레이어
>         D[실시간 데이터 수집]
>         E[실시간 처리]
>     end
>     subgraph 서빙 레이어
>         F[데이터 조회]
>     end
>     A --> B --> C --> F
>     D --> E --> F
> 
> ```
>
> ### 카파 아키텍처(Kappa Architecture)
>
> **카파 아키텍처**는 람다 아키텍처의 복잡성을 줄이기 위해 제안된 아키텍처로, 모든 데이터를 스트림 형태로 처리하는 **단일 레이어** 구조이다. 배치 레이어를 제거하고 스피드 레이어만을 사용하여 실시간 및 과거 데이터를 통합 처리한다.
>
> 주요 특징은 다음과 같다:
>
> - **단순성**: 하나의 데이터 처리 파이프라인으로 로직의 중복 구현을 방지한다.
> - **유연성**: 실시간 처리 엔진을 사용하여 과거 데이터도 재처리할 수 있다.
> - **확장성**: 스트림 처리 시스템의 확장성을 활용한다.
>
> **카파 아키텍처 구조도:**
>
> ```mermaid
> graph LR
>     A[데이터 수집]
>     B[메시지 큐/로그 저장소]
>     C[스트림 처리 엔진]
>     D[데이터 조회]
>     A --> B --> C --> D
> 
> ```
>
> ---
>
> **요약하면**, 람다 아키텍처는 배치와 실시간 처리를 분리하여 정확성과 최신성을 모두 추구하지만 복잡성이 높다. 반면에 카파 아키텍처는 모든 데이터를 스트림으로 처리하여 단순하고 유연한 데이터 처리 파이프라인을 제공한다.
>
> ### 스트리밍 데이터 레이크(Streaming Data Lake)
>
> 이 아키텍처는 **스피드 레이어**에서 데이터의 저장과 처리를 모두 담당하여, 데이터의 단일 진실 공급원(SSOT, Single Source Of Truth)이 되는 것을 목표로 한다.
>
> 스트리밍 데이터 레이크에서는 별도의 배치 레이어나 서빙 레이어를 제거하고, 모든 데이터를 스피드 레이어에서 처리하고 저장한다. 이를 통해 데이터의 중복 저장과 로직의 파편화를 방지하고, 운영의 복잡성을 감소시킬 수 있다
>
> **스트리밍 데이터 레이크 구조도:**
>
> ```mermaid
> graph LR
>     A[데이터 수집]
>     B[스트림 플랫폼: 카프카]
>     C[스트림 처리 엔진]
>     D[데이터 소비자: 애플리케이션]
>     A --> B --> C --> D
>     B --> D
> ```
>
> 이 구조에서는 스트림 플랫폼이 데이터의 저장소 역할까지 수행하며, 데이터 소비자들은 이 플랫폼에서 직접 데이터를 조회하고 활용한다. 이는 데이터 파이프라인을 단순화하고, 데이터의 일관성과 신뢰성을 높이는 데 기여한다.
>
> ---
>
> **요약하면**, 스트리밍 데이터 레이크는 스피드 레이어를 중심으로 데이터의 저장과 처리를 일원화하여 단일한 데이터 소스를 제공하는 아키텍처이다. 이를 통해 데이터 처리의 복잡성을 줄이고 운영 효율성을 향상시킬 수 있다.
>

### 카프카의 활용과 생태계

카프카는 SK, 삼성, 카카오, 네이버 등 국내 기업뿐만 아니라 넷플릭스, 우버, 월마트 등 해외 기업에서도 활발하게 사용되고 있다. 오픈소스 생태계 속에서 지속적으로 발전하고 있으며, ksqlDB, REST Proxy, Burrow 등 다양한 도구와의 연동을 통해 활용 범위를 넓혀가고 있다.

스타트업에서도 카프카를 도입함으로써 안정성과 확장성을 확보할 수 있으며, 빠른 성장 속에서도 데이터 관련 작업을 효율적으로 관리할 수 있다.

### 결론

아파치 카프카는 대용량 데이터 처리와 실시간 데이터 스트림 관리에 최적화된 플랫폼으로, 현대의 복잡한 데이터 아키텍처에서 핵심적인 역할을 수행하고 있다. 지속적인 발전과 생태계 확장을 통해 카프카는 미래의 데이터 레이크 아키텍처에서도 중요한 위치를 차지할 것으로 기대된다.